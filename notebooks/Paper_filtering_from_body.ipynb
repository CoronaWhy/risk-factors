{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Paper filtering from body.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3apk7hip3tED",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and extracts sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhsUSXHu2QKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "os.system('pip install scholarly')\n",
        "import scholarly\n",
        "# os.chdir('C:\\\\Users\\\\Cafral\\\\Desktop\\\\kaggle\\\\CORD-19-research-challenge\\\\data_v7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBlRE1Ep4V2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "e67677fe-269b-4d3a-b53c-4e8b829f7955"
      },
      "source": [
        "# Downloading all datasets\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "f = open(\"kaggle.json\", \"w\")\n",
        "f.write('{\"username\":\"pranjalya\",\"key\":\"fa4deb4f89e2fe282a3e29c166413ecf\"}')\n",
        "f.close()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d skylord/coronawhy\n",
        "!kaggle datasets download allen-institute-for-ai/CORD-19-research-challenge -f metadata.csv\n",
        "!unzip metadata.csv.zip\n",
        "!rm -rf metadata.csv.zip\n",
        "!unzip coronawhy.zip v6_text/*\n",
        "!wget -O v7_text.json https://storage.googleapis.com/coronawhy/NLPDatasets/v7_preprocessed/v7_text.json\n",
        "\n",
        "PATH = \"v6_text/v6_text/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coronawhy.zip to /content\n",
            "100% 12.7G/12.8G [03:26<00:00, 91.1MB/s]\n",
            "100% 12.8G/12.8G [03:26<00:00, 66.3MB/s]\n",
            "Downloading metadata.csv.zip to /content\n",
            " 33% 9.00M/27.6M [00:00<00:00, 55.2MB/s]\n",
            "100% 27.6M/27.6M [00:00<00:00, 104MB/s] \n",
            "Archive:  metadata.csv.zip\n",
            "  inflating: metadata.csv            \n",
            "Archive:  coronawhy.zip\n",
            "  inflating: v6_text/v6_text/v6_text_0.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_1.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_10.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_11.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_12.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_13.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_14.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_15.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_16.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_17.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_18.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_19.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_2.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_3.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_4.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_5.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_6.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_7.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_8.pkl  \n",
            "  inflating: v6_text/v6_text/v6_text_9.pkl  \n",
            "--2020-04-13 06:07:54--  https://storage.googleapis.com/coronawhy/NLPDatasets/v7_preprocessed/v7_text.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85684359 (82M) [application/json]\n",
            "Saving to: ‘v7_text.json’\n",
            "\n",
            "v7_text.json        100%[===================>]  81.71M   110MB/s    in 0.7s    \n",
            "\n",
            "2020-04-13 06:07:55 (110 MB/s) - ‘v7_text.json’ saved [85684359/85684359]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjLA-wWV5oSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "firstpass = True\n",
        "\n",
        "for pkl in os.listdir(PATH):\n",
        "  df = pd.read_pickle(PATH+pkl, compression='gzip')\n",
        "  if(firstpass):\n",
        "    v7_data = pd.read_json('v7_text.json')\n",
        "    df_method = pd.concat([v7_data[v7_data['section']=='methods'], df[df['section']=='methods']])\n",
        "    df_result = pd.concat([v7_data[v7_data['section']=='results'], df[df['section']=='results']])\n",
        "    firstpass = False\n",
        "  else:\n",
        "    df_method = pd.concat([df_method, df[df['section']=='methods']])\n",
        "    df_result = pd.concat([df_result, df[df['section']=='results']])\n",
        "\n",
        "df_method.to_csv('method_df.csv')\n",
        "df_result.to_csv('result_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQu-7C62QKo",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w4Qq6Vd2QKq",
        "colab_type": "code",
        "outputId": "fd677dd5-fa4e-42bd-bb34-f07e719b28b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "df_method = pd.read_csv('method_df.csv')\n",
        "df_result = pd.read_csv('result_df.csv')\n",
        "\n",
        "print(\"No of unique papers in method section : \", df_method['paper_id'].nunique(), \" out of \", \n",
        "      len(df_method), \" rows in dataframe\")\n",
        "print(\"No of unique papers in result section : \", df_result['paper_id'].nunique(), \" out of \", \n",
        "      len(df_result), \" rows in dataframe\")\n",
        "\n",
        "df_method.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No of unique papers in method section :  9693  out of  188137  rows in dataframe\n",
            "No of unique papers in result section :  7820  out of  178851  rows in dataframe\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 188137 entries, 0 to 188136\n",
            "Data columns (total 38 columns):\n",
            " #   Column                           Non-Null Count   Dtype \n",
            "---  ------                           --------------   ----- \n",
            " 0   Unnamed: 0                       188137 non-null  int64 \n",
            " 1   paper_id                         188137 non-null  object\n",
            " 2   language                         188137 non-null  object\n",
            " 3   section                          188137 non-null  object\n",
            " 4   sentence                         188137 non-null  object\n",
            " 5   lemma                            188137 non-null  object\n",
            " 6   UMLS                             188137 non-null  object\n",
            " 7   GGP                              188137 non-null  object\n",
            " 8   SO                               188137 non-null  object\n",
            " 9   TAXON                            188137 non-null  object\n",
            " 10  CHEBI                            188137 non-null  object\n",
            " 11  GO                               188137 non-null  object\n",
            " 12  CL                               188137 non-null  object\n",
            " 13  DNA                              188137 non-null  object\n",
            " 14  CELL_TYPE                        188137 non-null  object\n",
            " 15  CELL_LINE                        188137 non-null  object\n",
            " 16  RNA                              188137 non-null  object\n",
            " 17  PROTEIN                          188137 non-null  object\n",
            " 18  DISEASE                          188137 non-null  object\n",
            " 19  CHEMICAL                         188137 non-null  object\n",
            " 20  CANCER                           188137 non-null  object\n",
            " 21  ORGAN                            188137 non-null  object\n",
            " 22  TISSUE                           188137 non-null  object\n",
            " 23  ORGANISM                         188137 non-null  object\n",
            " 24  CELL                             188137 non-null  object\n",
            " 25  AMINO_ACID                       188137 non-null  object\n",
            " 26  GENE_OR_GENE_PRODUCT             188137 non-null  object\n",
            " 27  SIMPLE_CHEMICAL                  188137 non-null  object\n",
            " 28  ANATOMICAL_SYSTEM                188137 non-null  object\n",
            " 29  IMMATERIAL_ANATOMICAL_ENTITY     188137 non-null  object\n",
            " 30  MULTI-TISSUE_STRUCTURE           188137 non-null  object\n",
            " 31  DEVELOPING_ANATOMICAL_STRUCTURE  188137 non-null  object\n",
            " 32  ORGANISM_SUBDIVISION             188137 non-null  object\n",
            " 33  CELLULAR_COMPONENT               188137 non-null  object\n",
            " 34  PATHOLOGICAL_FORMATION           188137 non-null  object\n",
            " 35  ORGANISM_SUBSTANCE               188137 non-null  object\n",
            " 36  sentenc_id                       1047 non-null    object\n",
            " 37  sentence_id                      187090 non-null  object\n",
            "dtypes: int64(1), object(37)\n",
            "memory usage: 54.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhGWSk5t2QKy",
        "colab_type": "text"
      },
      "source": [
        "# Extracting sentences which contain topic ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoU1cb1a2QKz",
        "colab_type": "code",
        "outputId": "cc270da4-08bd-4ecb-f486-8f6bbe564ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def find_ngrams(dataframe, columnToSearch, keywords):\n",
        "    df_w_ngrams = dataframe[dataframe[columnToSearch].str.contains('|'.join(keywords), case=False) == True]\n",
        "    \n",
        "    return df_w_ngrams\n",
        "\n",
        "population_density_ngrams = ['population density','number of people in','number of people per',\n",
        "                             'highly populated areas','highly populated countries',\n",
        "                             'densely populated countries','densely populated areas',\n",
        "                             'high density areas','high density countries'\n",
        "                             ,'population densities', 'density of population','sparsely populated',\n",
        "                             'densely populated','density of the population','dense population',\n",
        "                             'populated areas', 'densely inhabited','housing density',\n",
        "                             'densely-populated','concentration of people', 'population pressure',\n",
        "                             'population studies','populated regions','populous',\n",
        "                             'high population densities','residential densities','overpopulated']\n",
        "\n",
        "#Extracting sentences which contain ngrams\n",
        "\n",
        "df_method_p = find_ngrams(df_method,'sentence',population_density_ngrams)\n",
        "\n",
        "df_result_p = find_ngrams(df_result,'sentence',population_density_ngrams)\n",
        "\n",
        "print(\"There are {} sentences containing keywords/ngrams in Method section.\".format(len(df_method_p)))\n",
        "print(\"There are {} sentences containing keywords/ngrams in Result section.\".format(len(df_result_p)))\n",
        "\n",
        "# Merging the method and result section sentences into single dataframe\n",
        "df_real = pd.concat([df_method_p, df_result_p])\n",
        "\n",
        "print(\"Total unique papers in Method section : {}\".format(df_method_p['paper_id'].nunique()))\n",
        "print(\"Total unique papers in Result section : {}\".format(df_result_p['paper_id'].nunique()))\n",
        "print(\"Total unique papers in combined section : {}\".format(df_real['paper_id'].nunique()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 121 sentences containing keywords/ngrams in Method section.\n",
            "There are 62 sentences containing keywords/ngrams in Result section.\n",
            "Total unique papers in Method section : 84\n",
            "Total unique papers in Result section : 39\n",
            "Total unique papers in combined section : 117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E-J4-0a2QK5",
        "colab_type": "text"
      },
      "source": [
        "# Keeping all the sentences from papers that had topic ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Gc3VhL2QK6",
        "colab_type": "code",
        "outputId": "9f682373-107c-4475-a0d6-4d417156ef7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_method_all_sentence = pd.merge(df_method[['paper_id','sentence']],df_method_p['paper_id'],on='paper_id',how='right')\n",
        "df_method_all_sentence.rename(columns={'sentence_x':'all_sentences','sentence_y':'ngram_sentence'},inplace=True)\n",
        "\n",
        "df_result_all_sentence = pd.merge(df_result[['paper_id','sentence']],df_result_p['paper_id'],on='paper_id',how='right')\n",
        "df_result_all_sentence.rename(columns={'sentence_x':'all_sentences','sentence_y':'ngram_sentence'},inplace=True)\n",
        "\n",
        "df_all_sentences = pd.concat([df_method_all_sentence, df_result_all_sentence])\n",
        "print(\"Total unique papers in combined section : {}\".format(df_all_sentences['paper_id'].nunique()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique papers in combined section : 117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNFZxy-C2QK_",
        "colab_type": "text"
      },
      "source": [
        "# Extracting methodolody, sample size, causal nature, sentences refering to coronavirus, fatality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fYJnfrV2QLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(ngramDf,allSentdataFrame):\n",
        "    # extracting methodology\n",
        "    methods_list = ['regression','OLS','logistic','time series','model','modelling','simulation',\n",
        "                    'forecast','forecasting']\n",
        "    methodology = find_ngrams(allSentdataFrame,'sentence',methods_list)\n",
        "\n",
        "    #extracting sample size\n",
        "    sample_size_list = ['population size','sample size','number of samples','number of observations',\n",
        "                        'number of subjects']\n",
        "    sample_size = find_ngrams(allSentdataFrame, 'sentence', sample_size_list)\n",
        "\n",
        "    #extracting nature of correlation\n",
        "    causal_list =['statistically significant','statistical significance',\n",
        "                  'correlation','positively correlated','negatively correlated','correlated',\n",
        "                  'p value','p-value','chi square','chi-square',\n",
        "                  'confidence interval','CI','odds ratio','OR','coefficient']\n",
        "\n",
        "    causality_type = find_ngrams(allSentdataFrame, 'sentence', causal_list)\n",
        "\n",
        "    # extracting coronavirus related sentence #can someone check and update this list?\n",
        "    coronavirus_list = ['severe acute respiratory syndrome','sars-cov','sars-like',\n",
        "                        'middle east respiratory syndrome','mers-cov','mers-like',\n",
        "                        'covid-19','sars-cov-2','2019-ncov','sars-2',\n",
        "                        'sarscov-2','novel coronavirus','corona virus','coronaviruses',\n",
        "                        'sars','mers','covid19','covid 19']\n",
        "\n",
        "    coronavirus = find_ngrams(allSentdataFrame, 'sentence', coronavirus_list)\n",
        "\n",
        "    # extracting outcome\n",
        "    disease_stage_list = ['lethal', 'morbid',\"death\", \"fatality\", \"mortality\",\"lethal\", \"lethality\", \"morbidity\"]\n",
        "\n",
        "    fatality = find_ngrams(allSentdataFrame, 'sentence', disease_stage_list)\n",
        "\n",
        "    df_list = [methodology,sample_size,causality_type,coronavirus,fatality]\n",
        "    df_list_name = ['methodology','sample_size','causality_type','coronavirus','fatality']\n",
        "    i=0\n",
        "    for one_df in df_list:\n",
        "        one_df.rename(columns={'sentence':df_list_name[i]},inplace=True)\n",
        "        print(one_df.head())\n",
        "        grouped_one_df = one_df.groupby('paper_id')[df_list_name[i]].sum()\n",
        "        ngramDf = pd.merge(ngramDf,grouped_one_df,on='paper_id',how='left')\n",
        "        i=i+1\n",
        "    return ngramDf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6wD7W5T2QLE",
        "colab_type": "code",
        "outputId": "6f7b8f88-f5dc-48c2-bcb3-e7a918b7a64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "df_real = extract_features(df_real, df_all_sentences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                   paper_id                                        methodology\n",
            "0  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "2  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "4  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "6  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "8  dbd4b4192c4b4a84d3b3b6e1f82a56d5351aaa20  The dynamic model (7) is impossible to solve a...\n",
            "                                      paper_id                                        sample_size\n",
            "604   6445688d3f59cb7e02f2a8b28450cdf118a8a373  On a population level that means that the tota...\n",
            "676   955b36f4b007abbfaa28385a627b03e2102313d9  Such an analysis was not feasible in this stud...\n",
            "1028  873d2ca5817ad916b491680ffc9e3260a8469e60  The population living in urban slums is report...\n",
            "1043  873d2ca5817ad916b491680ffc9e3260a8469e60  We chose these urban centers based on populati...\n",
            "1071  873d2ca5817ad916b491680ffc9e3260a8469e60  The population living in urban slums is report...\n",
            "                                   paper_id                                     causality_type\n",
            "0  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "2  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "4  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "6  a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "9  dbd4b4192c4b4a84d3b3b6e1f82a56d5351aaa20  The method we have opted for is 2 nd order Run...\n",
            "                                    paper_id                                        coronavirus\n",
            "0   a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "2   a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "4   a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "6   a98b1b317a570c905d9feff5bedd079effe89a7a  Basic transmission dynamics of COVID-19 was mo...\n",
            "29  dbd4b4192c4b4a84d3b3b6e1f82a56d5351aaa20  For τ2, Reference [43] reports that patients a...\n",
            "                                     paper_id                                           fatality\n",
            "342  de36857b220e50ff58ec26a8b0b7877043633332  Though less deadly than similar Ebola virus ou...\n",
            "526  ce6717ad3bb0da86077a5cbb8111576ea8230b2c  For each patient we collected the following ch...\n",
            "752  5f00c7471a968e0b8d9176a2f7fc65184948e636  International Health Regulation (IHR) notifica...\n",
            "754  5f00c7471a968e0b8d9176a2f7fc65184948e636  Source: Public Health Agency of Canada (5), th...\n",
            "756  5f00c7471a968e0b8d9176a2f7fc65184948e636  Secondary cases generally present with milder ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYGHOvoP2QLJ",
        "colab_type": "text"
      },
      "source": [
        "# Merge with Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egb5POD02QLK",
        "colab_type": "code",
        "outputId": "08bd5a2f-ff5e-4de5-e20f-762d2ea8cb60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "metadata = pd.read_csv('metadata.csv')\n",
        "metadata.rename(columns={'sha':'paper_id'}, inplace = True)\n",
        "metadata['paper_id'] = metadata['paper_id'].astype(\"str\")\n",
        "\n",
        "#Merging the given papers with their metadata\n",
        "df_real = df_real.merge(metadata[['paper_id', 'title', 'abstract', 'publish_time', 'authors',\n",
        "                                  'url']], on='paper_id', how='left') #'title_w_ngram','abstract_w_ngram'\n",
        "\n",
        "#Keeping only the fields which are relevant to us.\n",
        "df_real = df_real[['paper_id','language', 'section', 'sentence', 'lemma', 'UMLS', 'sentence_id', \n",
        "                   'publish_time', 'authors', 'url','methodology','sample_size','causality_type','coronavirus',\n",
        "                   'fatality','title','abstract','publish_time','authors',\n",
        "                   'url','TAXON']]#'title_w_ngram','abstract_w_ngram',\n",
        "df_real.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 183 entries, 0 to 182\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   paper_id        183 non-null    object\n",
            " 1   language        183 non-null    object\n",
            " 2   section         183 non-null    object\n",
            " 3   sentence        183 non-null    object\n",
            " 4   lemma           183 non-null    object\n",
            " 5   UMLS            183 non-null    object\n",
            " 6   sentence_id     181 non-null    object\n",
            " 7   publish_time    142 non-null    object\n",
            " 8   authors         141 non-null    object\n",
            " 9   url             142 non-null    object\n",
            " 10  methodology     116 non-null    object\n",
            " 11  sample_size     46 non-null     object\n",
            " 12  causality_type  183 non-null    object\n",
            " 13  coronavirus     40 non-null     object\n",
            " 14  fatality        34 non-null     object\n",
            " 15  title           142 non-null    object\n",
            " 16  abstract        141 non-null    object\n",
            " 17  publish_time    142 non-null    object\n",
            " 18  authors         141 non-null    object\n",
            " 19  url             142 non-null    object\n",
            " 20  TAXON           183 non-null    object\n",
            "dtypes: object(21)\n",
            "memory usage: 31.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrpEVykM2QLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = df_real.groupby('paper_id')\n",
        "def keywordcounter(sentences, keywords_list):\n",
        "    '''\n",
        "    Input : List of sentences, List of keywords\n",
        "    Returns : Keywords present in sentences, Total count of all keywords present in Input\n",
        "    '''\n",
        "    keyword = {}\n",
        "    sent = \" \".join(sentences)\n",
        "    for pol in keywords_list:\n",
        "        counter = sent.lower().count(pol)\n",
        "        if (counter > 0):\n",
        "            keyword[pol] = counter\n",
        "    return list(keyword.keys()), sum(keyword.values())\n",
        "\n",
        "def aggregation(item,keyWordList,RiskFactor):\n",
        "    '''\n",
        "    Input : Dataframe of sentences of a paper\n",
        "    Return : Datframe in Standard Output format\n",
        "    '''\n",
        "    dfo = {}\n",
        "    \n",
        "    dfo['Risk Factor'] = RiskFactor\n",
        "    dfo['Title'] = item['title'].iloc[0]\n",
        "    dfo['Keyword/Ngram'], dfo['No of keyword occurence in Paper'] = keywordcounter(item['sentence'].tolist(),\n",
        "                                                                                 keyWordList)\n",
        "    dfo['paper_id'] = item['paper_id'].iloc[0]\n",
        "    \n",
        "    if (item['url'].iloc[0].isnull().any()==False):\n",
        "        dfo['URL'] = item['url'].iloc[0].tolist()\n",
        "    else:\n",
        "        dfo['URL']=''\n",
        "    #dfo['Sentences from Title']= item['title_w_ngram'].iloc[0]                        \n",
        "    #dfo['Sentences from Abstract']= item['abstract_w_ngram'].iloc[0]\n",
        "    dfo['Sentences from Method'] = item[item['section']=='methods']['sentence'].tolist()\n",
        "    dfo['Sentences from Result'] = item[item['section']=='results']['sentence'].tolist()\n",
        "    \n",
        "    if (item['authors'].iloc[0].isnull().any()==False):#(item['authors'].iloc[0].isnull()==False):\n",
        "        dfo['Authors'] = item['authors'].iloc[0].tolist()\n",
        "    else:\n",
        "         dfo['Authors'] = ''\n",
        "    # For papers which do not have title (not in metadata) we have to resolve exceptions\n",
        "    try:\n",
        "        dfo['No of Citations'] = next(scholarly.search_pubs_query(item['title'].iloc[0])).citedby\n",
        "    except:\n",
        "        dfo['No of Citations'] = 0\n",
        "        \n",
        "    dfo['Correlation'] = item['causality_type'].iloc[0]\n",
        "    dfo['Design Methodology'] = item['methodology'].iloc[0]\n",
        "    dfo['Sample Size'] = item['sample_size'].iloc[0]\n",
        "    dfo['Coronavirus'] = item['coronavirus'].iloc[0]\n",
        "    dfo['Fatality'] = item['fatality'].iloc[0]\n",
        "    dfo['TAXON'] =item['TAXON'].iloc[0]\n",
        "    \n",
        "    return dfo\n",
        "\n",
        "df_output = pd.DataFrame(columns=['Risk Factor', 'Title','Keyword/Ngram', 'No of keyword occurence in Paper',\n",
        "                                  'paper_id', 'URL',\n",
        "                                  'Sentences from Result', 'Sentences from Method',\n",
        "                                  'Authors','No of Citations', 'Correlation', \n",
        "                                  'Design Methodology', 'Sample Size',\n",
        "                                 'Coronavirus','Fatality','TAXON'])\n",
        "for key, item in grouped:\n",
        "    df_output = pd.concat([df_output, pd.DataFrame([aggregation(item,population_density_ngrams,'Population Density')])])\n",
        "\n",
        "df_output = df_output.reset_index()\n",
        "df_output.to_excel('population_density_json.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9diXvX432QLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "506a84ea-562e-480b-eed6-0abd202ed90e"
      },
      "source": [
        "df_output.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Risk Factor</th>\n",
              "      <th>Title</th>\n",
              "      <th>Keyword/Ngram</th>\n",
              "      <th>No of keyword occurence in Paper</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>URL</th>\n",
              "      <th>Sentences from Result</th>\n",
              "      <th>Sentences from Method</th>\n",
              "      <th>Authors</th>\n",
              "      <th>No of Citations</th>\n",
              "      <th>Correlation</th>\n",
              "      <th>Design Methodology</th>\n",
              "      <th>Sample Size</th>\n",
              "      <th>Coronavirus</th>\n",
              "      <th>Fatality</th>\n",
              "      <th>TAXON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Population Density</td>\n",
              "      <td>Distribution and Risk Factors of 2009 Pandemic...</td>\n",
              "      <td>[population density]</td>\n",
              "      <td>3</td>\n",
              "      <td>043aa68f2c784899f71225e8eb233150760a6a54</td>\n",
              "      <td>[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC...</td>\n",
              "      <td>[Population density and the density of medical...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Fang, Li-Qun; Wang, Li-Ping; de Vlas, Sake J....</td>\n",
              "      <td>0</td>\n",
              "      <td>A total of 121,805 cases of pandemic influenza...</td>\n",
              "      <td>Table 2 shows that all climatic factors (excep...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The first death caused by pandemic influenza w...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Population Density</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[population density]</td>\n",
              "      <td>1</td>\n",
              "      <td>0900c2c26866f1fed9afc70835e4df7f453c39c7</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[20 The results are not sensitive to using dis...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>This section describes the empirical model use...</td>\n",
              "      <td>This section describes the empirical model use...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We are particularly interested in examining wh...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Population Density</td>\n",
              "      <td>Spatiotemporal diffusion of influenza A (H1N1)...</td>\n",
              "      <td>[population density, populous]</td>\n",
              "      <td>2</td>\n",
              "      <td>0f76bdee678e512d5bfb2d3597ad57a1b5d74bc4</td>\n",
              "      <td>[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC...</td>\n",
              "      <td>[Population density, municipal road transport,...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[da Costa, Ana Carolina Carioca; Codeço, Cláud...</td>\n",
              "      <td>0</td>\n",
              "      <td>The spatial distribution of influenza A (H1N1)...</td>\n",
              "      <td>Table 1 shows the effects of covariates that w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The actions recommended for this phase were ai...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Population Density</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[population density]</td>\n",
              "      <td>1</td>\n",
              "      <td>13bea4e60e6161f1132a83bc5ed2b3bceab1e05e</td>\n",
              "      <td></td>\n",
              "      <td>[We established replicate bacterial population...</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>We established replicate bacterial populations...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Conversely, adaptation of zoonotic parasites t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['bacterial', 'host', 'bacteria']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Population Density</td>\n",
              "      <td>Natural history and epidemiology of respirator...</td>\n",
              "      <td>[densely populated]</td>\n",
              "      <td>1</td>\n",
              "      <td>140c32554663e4033d23a392bd287b0239bfe1d1</td>\n",
              "      <td>[https://doi.org/10.1016/j.vaccine.2015.08.048...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[It is located in the low-income and densely p...</td>\n",
              "      <td>[Halasa, Natasha; Williams, John; Faouri, Sami...</td>\n",
              "      <td>0</td>\n",
              "      <td>We conducted a prospective, year-round viral s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Amman']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                              TAXON\n",
              "0      0  ...                                 []\n",
              "1      0  ...                                 []\n",
              "2      0  ...                                 []\n",
              "3      0  ...  ['bacterial', 'host', 'bacteria']\n",
              "4      0  ...                          ['Amman']\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}